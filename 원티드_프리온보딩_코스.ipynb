{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "원티드 프리온보딩 코스.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### **문제 1) Tokenizer 생성하기**\n",
        "\n",
        "**1-1. `preprocessing()`**\n",
        "\n",
        "텍스트 전처리를 하는 함수입니다.\n",
        "\n",
        "- input: 여러 영어 문장이 포함된 list 입니다. ex) ['I go to school.', 'I LIKE pizza!']\n",
        "- output: 각 문장을 토큰화한 결과로, nested list 형태입니다. ex) [['i', 'go', 'to', 'school'], ['i', 'like', 'pizza']]\n",
        "- 조건 1: 입력된 문장에 대해서 소문자로의 변환과 특수문자 제거를 수행합니다.\n",
        "- 조건 2: 토큰화는 white space 단위로 수행합니다."
      ],
      "metadata": {
        "id": "OBo2vSw5RuKn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1-2. `fit()`**\n",
        "\n",
        "어휘 사전을 구축하는 함수입니다.\n",
        "\n",
        "- input: 여러 영어 문장이 포함된 list 입니다. ex) ['I go to school.', 'I LIKE pizza!']\n",
        "- 조건 1: 위에서 만든 `preprocessing` 함수를 이용하여 각 문장에 대해 토큰화를 수행합니다.\n",
        "- 조건 2: 각각의 토큰을 정수 인덱싱 하기 위한 어휘 사전(`self.word_dict`)을 생성합니다.\n",
        "    - 주어진 코드에 있는 `self.word_dict`를 활용합니다."
      ],
      "metadata": {
        "id": "a4-oBkIfYiDO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1-3. `transform()`**\n",
        "\n",
        "어휘 사전을 활용하여 입력 문장을 정수 인덱싱하는 함수입니다.\n",
        "\n",
        "- input: 여러 영어 문장이 포함된 list입니다. ex) ['I go to school.', 'I LIKE pizza!']\n",
        "- output: 각 문장의 정수 인덱싱으로, nested list 형태입니다. ex) [[1, 2, 3, 4], [1, 5, 6]]\n",
        "- 조건 1: 어휘 사전(`self.word_dict`)에 없는 단어는 'oov'의 index로 변환합니다."
      ],
      "metadata": {
        "id": "njuc7woWsM_o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "class Tokenizer():\n",
        "  def __init__(self):\n",
        "    self.word_dict = {'oov': 0}\n",
        "    self.fit_checker = False\n",
        "  \n",
        "  def preprocessing(self, sequences):\n",
        "    result = []\n",
        "    regex = \"[^a-zA-Z0-9^]\"\n",
        "    subst = \" \"\n",
        "    # 정규식 적용\n",
        "    for i in sequences :\n",
        "      token = re.sub(regex, subst, i)\n",
        "      # 소문자로 치환\n",
        "      token = token.lower().split()\n",
        "      result.append(token)\n",
        "    return result\n",
        "  \n",
        "  def fit(self, sequences):\n",
        "    self.fit_checker = False\n",
        "    '''\n",
        "    문제 1-2.\n",
        "    '''\n",
        "    tokens=self.preprocessing(sequences)\n",
        "    \n",
        "    #순서대로 어휘 사전 작성 위해 count 정의\n",
        "    count=1\n",
        "    \n",
        "    for sent in tokens:   #문장 리스트에서 하나의 문장 가져오기\n",
        "      for word in sent:   #하나의 문장에서 하나의 단어 가져오기\n",
        "        if word not in self.word_dict.keys():   #어휘 사전에 단어가 없는 경우,\n",
        "          self.word_dict[word] = count   #순서대로 어휘 등록\n",
        "          count+=1  #등록된 다음 인덱스 번호를 더해줌\n",
        "        else:\n",
        "          pass\n",
        "    self.fit_checker = True\n",
        "  \n",
        "  def transform(self, sequences):\n",
        "    # 인덱싱 된 번호를 출력하기 위한 리스트 정의\n",
        "    result = []\n",
        "    tokens = self.preprocessing(sequences)\n",
        "    if self.fit_checker:\n",
        "      '''\n",
        "      문제 1-3.\n",
        "      '''\n",
        "      for sent in tokens:\n",
        "        encode = []   #하나의 문장의 단어들을 인덱싱하여 저장하기 위한 리스트 정의\n",
        "        for word in sent:\n",
        "          if word in self.word_dict.keys():\n",
        "            word = self.word_dict[word]   #정수 인덱싱\n",
        "          else:\n",
        "            word = self.word_dict['oov']   #oov의 값을 등록 안된 단어에 대입\n",
        "            '''\n",
        "            (참고용)아래의 코드를 사용하면 2개 이상의 등록되지 않은 단어도 다르게 사전에 등록하면서 사용가능.\n",
        "\n",
        "            self.word_dict['oov'] = len(word_dict)+1  # oov의 값을 사전에 등록된 값보다 1 크게 유지 #fit 과정에서 사용\n",
        "            self.word_dict[word] = self.word_dict['oov'] # 사전에 oov의 값으로 새로운 단어 등록\n",
        "            self_word_dict[word] += 1 # 사전에 등록된 값보다 1 크게 유지\n",
        "            '''\n",
        "          encode.append(word)   #한 문장안의 단어들을 인덱싱하여 저장\n",
        "        result.append(encode)   #인덱싱 된 리스트를 저장\n",
        "      return result\n",
        "    else:\n",
        "      raise Exception(\"Tokenizer instance is not fitted yet.\")\n",
        "      \n",
        "  def fit_transform(self, sequences):\n",
        "    self.fit(sequences)\n",
        "    result = self.transform(sequences)\n",
        "    return result"
      ],
      "metadata": {
        "id": "eYek4MMPtFE5"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences=['I go to school.', 'I LIKE pizza!','i go to room!','they have a pizza', 'i have to go!']\n",
        "#sequences=['I go to school.', 'I LIKE pizza!']\n",
        "tokenizer = Tokenizer()\n",
        "processing = tokenizer.preprocessing(sequences)\n",
        "print(\"전처리 과정 후 :\",processing)\n",
        "tokenizer.fit(sequences)\n",
        "trans = tokenizer.transform(sequences)\n",
        "print(\"정수 인덱싱 후 :\" ,trans)\n",
        "print(\"완성된 어휘 사전 :\",tokenizer.word_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ahDe6IlYNezu",
        "outputId": "cd5db4f1-36fe-4166-8192-ac5223537132"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "전처리 과정 후 : [['i', 'go', 'to', 'school'], ['i', 'like', 'pizza'], ['i', 'go', 'to', 'room'], ['they', 'have', 'a', 'pizza'], ['i', 'have', 'to', 'go']]\n",
            "정수 인덱싱 후 : [[1, 2, 3, 4], [1, 5, 6], [1, 2, 3, 7], [8, 9, 10, 6], [1, 9, 3, 2]]\n",
            "완성된 어휘 사전 : {'oov': 0, 'i': 1, 'go': 2, 'to': 3, 'school': 4, 'like': 5, 'pizza': 6, 'room': 7, 'they': 8, 'have': 9, 'a': 10}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **문제 2) TfidfVectorizer 생성하기**\n",
        "\n",
        "**2-1. `fit()`**\n",
        "\n",
        "입력 문장들을 이용해 IDF 행렬을 만드는 함수입니다.\n",
        "\n",
        "- input: 여러 영어 문장이 포함된 list 입니다. ex) ['I go to school.', 'I LIKE pizza!']\n",
        "- 조건 1: IDF 행렬은 list 형태입니다.\n",
        "    - ex) [토큰1에 대한 IDF 값, 토큰2에 대한 IDF 값, .... ]\n",
        "- 조건 2: IDF 값은 아래 식을 이용해 구합니다.\n",
        "    \n",
        "    $$\n",
        "    idf(d,t)=log_e(\\frac{n}{1+df(d,t)})\n",
        "    $$\n",
        "    \n",
        "    - $df(d,t)$ : 단어 t가 포함된 문장 d의 개수\n",
        "    - $n$ : 입력된 전체 문장 개수\n",
        "- 조건 3: 입력된 문장의 토큰화에는 문제 1에서 만든 Tokenizer를 사용합니다."
      ],
      "metadata": {
        "id": "sUruzbcMYEvI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2-2. `transform()`**\n",
        "\n",
        "입력 문장들을 이용해 TF-IDF 행렬을 만드는 함수입니다.\n",
        "\n",
        "- input: 여러 영어 문장이 포함된 list입니다. ex) ['I go to school.', 'I LIKE pizza!']\n",
        "- output : nested list 형태입니다.\n",
        "    \n",
        "    \n",
        "    |  | 토큰1 | 토큰2 | 토큰3 |\n",
        "    | --- | --- | --- | --- |\n",
        "    | 문장1 | tf-idf(1,1) | tf-idf(1,2) | tf-idf(1,3) |\n",
        "    | 문장2 | tf-idf(2,1) | tf-idf(2,2) | tf-idf(2,3) |\n",
        "- 조건1 : 입력 문장을 이용해 TF 행렬을 만드세요.\n",
        "    - $tf(d, t)$ : 문장 d에 단어 t가 나타난 횟수\n",
        "- 조건2 : 문제 2-1( `fit()`)에서 만든 IDF 행렬과 아래 식을 이용해 TF-IDF 행렬을 만드세요\n",
        "    \n",
        "    $$\n",
        "    tf-idf(d,t) = tf(d,t) \\times idf(d,t)\n",
        "    $$"
      ],
      "metadata": {
        "id": "8Pimn5IRYKs-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### 하나의 고유한 토큰당 IDF가 나와야함 고쳐야할 부분\n",
        "from collections import Counter\n",
        "from math import log\n",
        "import pandas as pd\n",
        "\n",
        "class TfidfVectorizer:\n",
        "  def __init__(self, tokenizer):\n",
        "    self.tokenizer = tokenizer\n",
        "    self.fit_checker = False\n",
        "    self.N = len(sequences) # 총 문장 개수 변수 지정\n",
        "    self.vocab_IDF=[] #IDF 값 저장할 리스트 변수 지정\n",
        "\n",
        "  def fit(self, sequences):\n",
        "    tokenized = self.tokenizer.fit_transform(sequences)\n",
        "    '''\n",
        "    문제 2-1.\n",
        "    '''\n",
        "    # 고유 token 값 구하기\n",
        "    tokens = set(sum(tokenized, []))\n",
        "    \n",
        "    # IDF 구하기 (log(N/1+DF))\n",
        "    # 토큰 1개당 전체 문장에 몇번 들어가있는지 확인하고 IDF값 도출\n",
        "    # 오류발생 예제) 전체 문장이 4개 일때, 'i'라는 토큰이 3문장에서 발견되면 log(4/(3+1))으로 0으로 귀결되어 가중치 오류 발생\n",
        "    for token in tokens:\n",
        "      df = 0\n",
        "      for sent in tokenized:   \n",
        "        if sent.count(token) > 0 :\n",
        "          df += 1\n",
        "      self.vocab_IDF.append(log(self.N/(df+1)))\n",
        "    \n",
        "    self.fit_checker = True\n",
        "    \n",
        "\n",
        "  def transform(self, sequences):\n",
        "    if self.fit_checker:\n",
        "      tokenized = self.tokenizer.transform(sequences)\n",
        "      '''\n",
        "      문제 2-2.\n",
        "      '''\n",
        "      # 고유 token 값 구하기\n",
        "      tokens = list(set(sum(tokenized, [])))\n",
        "\n",
        "      #TF-IDF 구하기 (tf * idf)\n",
        "      result =[]\n",
        "      for i in range(self.N):\n",
        "        result.append([])\n",
        "        sent = tokenized[i]\n",
        "        for num in range(len(tokens)) :\n",
        "          token = tokens[num]\n",
        "          tf = sent.count(token)  #TF값 구하기\n",
        "          idf = self.vocab_IDF[num]  #저장한 IDF값 불러오기\n",
        "          result[-1].append(tf*idf)  #비어있는 []에 tf-idf값 저장\n",
        "\n",
        "      self.tfidf_matrix = result\n",
        "\n",
        "      return self.tfidf_matrix\n",
        "\n",
        "    else:\n",
        "      raise Exception(\"TfidfVectorizer instance is not fitted yet.\")\n",
        "\n",
        "  \n",
        "  def fit_transform(self, sequences):\n",
        "    self.fit(sequences)\n",
        "    return self.transform(sequences)"
      ],
      "metadata": {
        "id": "ogN89a1hYvH_"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf= TfidfVectorizer(tokenizer)"
      ],
      "metadata": {
        "id": "jpmbQGUXrVKq"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf.fit(sequences)"
      ],
      "metadata": {
        "id": "eNy5qZLOretc"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t=tfidf.transform(sequences)"
      ],
      "metadata": {
        "id": "lGoS-mL8s0ob"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#IDF 값 확인하기\n",
        "tfidf.vocab_IDF"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Rxu0gBSDRVN",
        "outputId": "b8aec539-3e54-4837-9c59-b3246db20f26"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0,\n",
              " 0.22314355131420976,\n",
              " 0.22314355131420976,\n",
              " 0.9162907318741551,\n",
              " 0.9162907318741551,\n",
              " 0.5108256237659907,\n",
              " 0.9162907318741551,\n",
              " 0.9162907318741551,\n",
              " 0.5108256237659907,\n",
              " 0.9162907318741551]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#TF-IDF 데이터프레임으로 확인하기\n",
        "pd.DataFrame(t, index=sequences, columns=range(1,11))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "fTmvJl5xBkeY",
        "outputId": "6cffa3e1-e87a-4b95-cb4b-8580ebea18ed"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-6a041dab-0e4c-4720-bbb9-cd0a50fe54a5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>I go to school.</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.223144</td>\n",
              "      <td>0.223144</td>\n",
              "      <td>0.916291</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I LIKE pizza!</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.916291</td>\n",
              "      <td>0.510826</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>i go to room!</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.223144</td>\n",
              "      <td>0.223144</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.916291</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>they have a pizza</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.510826</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.916291</td>\n",
              "      <td>0.510826</td>\n",
              "      <td>0.916291</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>i have to go!</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.223144</td>\n",
              "      <td>0.223144</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.510826</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6a041dab-0e4c-4720-bbb9-cd0a50fe54a5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6a041dab-0e4c-4720-bbb9-cd0a50fe54a5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6a041dab-0e4c-4720-bbb9-cd0a50fe54a5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                    1         2         3   ...        8         9         10\n",
              "I go to school.    0.0  0.223144  0.223144  ...  0.000000  0.000000  0.000000\n",
              "I LIKE pizza!      0.0  0.000000  0.000000  ...  0.000000  0.000000  0.000000\n",
              "i go to room!      0.0  0.223144  0.223144  ...  0.000000  0.000000  0.000000\n",
              "they have a pizza  0.0  0.000000  0.000000  ...  0.916291  0.510826  0.916291\n",
              "i have to go!      0.0  0.223144  0.223144  ...  0.000000  0.510826  0.000000\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#어휘 사전 확인\n",
        "tokenizer.word_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SlJlPNV_CMP1",
        "outputId": "7c41c027-a1e9-42f4-d7ea-6ba0a166bb04"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'a': 10,\n",
              " 'go': 2,\n",
              " 'have': 9,\n",
              " 'i': 1,\n",
              " 'like': 5,\n",
              " 'oov': 0,\n",
              " 'pizza': 6,\n",
              " 'room': 7,\n",
              " 'school': 4,\n",
              " 'they': 8,\n",
              " 'to': 3}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    }
  ]
}